{
    "model": {
        "model_dim" : 128,
        "num_heads" : 8,
        "num_layers": 3,
        "output_dim": 400
    },
    "training": {
        "lr"            : 0.00005,
        "num_epochs"    : 2000,
        "save_epochs"   : 1000,
        "batch_size"    : 256,
        "num_workers"   : 10
    },
    "pretrain": {
        "num_epochs": 3000,
        "lr"        : "0.0001",
        "batch_size": 256
    }
}